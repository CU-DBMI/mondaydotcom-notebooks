{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19f92b40",
   "metadata": {},
   "source": [
    "# Validate Monday.com tasks for integration issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2baec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import prefect\n",
    "from prefect import task, Flow, Parameter, unmapped\n",
    "from prefect.executors import LocalExecutor, LocalDaskExecutor\n",
    "from prefect.utilities.logging import get_logger\n",
    "\n",
    "from datetime import timedelta, datetime\n",
    "from box import Box\n",
    "\n",
    "from mondaydotcom_utils.formatted_value import (\n",
    "    FormattedValue,\n",
    "    get_col_defs,\n",
    "    get_items_by_board,\n",
    ")\n",
    "\n",
    "# uses the pretty okay SDK here: https://github.com/ProdPerfect/monday\n",
    "from monday import MondayClient\n",
    "\n",
    "import scrapbook as sb\n",
    "import dotenv\n",
    "\n",
    "from io import StringIO\n",
    "from IPython import get_ipython\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828fb7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed vars\n",
    "TASKS_BOARD_ID = \"1883170887\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e05e7",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "environment = \"dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0b4d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the environment vars for secrets\n",
    "\n",
    "env_file = f\".env-{environment}\"\n",
    "logger.info(\"Loading the .env file from %s\", env_file)\n",
    "dotenv.load_dotenv(dotenv.find_dotenv(env_file))\n",
    "\n",
    "assert os.environ.get(\"MONDAY_KEY\"), f\"MONDAY_KEY not found in {env_file}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6273af4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = MondayClient(os.environ.get(\"MONDAY_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4375fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get done tasks\n",
    "# tasks_df = get_items_by_board(conn, TASKS_BOARD_ID, \"status\", \"Done\")\n",
    "tasks_df = get_items_by_board(conn, TASKS_BOARD_ID)\n",
    "\n",
    "# Do not include Posted tasks\n",
    "tasks_df = tasks_df.loc[\n",
    "    ~tasks_df[\"Integration Message\"].str.startswith(\"Posted\", na=False)\n",
    "]\n",
    "\n",
    "tasks_df.rename(\n",
    "    columns={\n",
    "        \"monday_id\": \"task_id\",\n",
    "        \"monday_name\": \"Task Name\",\n",
    "        \"Customer Project\": \"project_id\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "tasks_df = tasks_df.explode([\"project_id\"], ignore_index=True)\n",
    "tasks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e3490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_task_record(record):\n",
    "    \"\"\"\n",
    "    Validate checks individual records\n",
    "    and we'll use those rules to create journal records later.\n",
    "\n",
    "    Rules:\n",
    "      1. Either actual hours or sessions times are used, but not both.\n",
    "         If both are found, this is an error.\n",
    "      2. If actual hours is used, then the number of owners dictates the number\n",
    "         of journal records. E.g., actual hours = 15, with 3 owners, yields\n",
    "         three journal entries at 5 each (actual hours / owner count).\n",
    "         If no owners are found, this is an error.\n",
    "      3. If no time fields, either actual or sessions, this is a problem.\n",
    "\n",
    "      If session times are used, then a journal entry is created for each\n",
    "         session.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(record[\"Actual Time__additional_value\"], list):\n",
    "        sessions_list = record[\"Actual Time__additional_value\"]\n",
    "    else:\n",
    "        sessions_list = []\n",
    "\n",
    "    if isinstance(record[\"Owner\"], list):\n",
    "        owners_list = record[\"Owner\"]\n",
    "    else:\n",
    "        owners_list = []\n",
    "\n",
    "    actual_hours = record[\"Actual Hours\"]\n",
    "    len_sessions_list = len(sessions_list)\n",
    "    len_owners_list = len(owners_list)\n",
    "    title = record[\"Task Name\"]\n",
    "    project_id = record[\"project_id\"]\n",
    "\n",
    "    logger.debug(\n",
    "        \"actual_hours:%s, len(session_list):%s, len(owners_list):%s\",\n",
    "        actual_hours,\n",
    "        len_sessions_list,\n",
    "        len_owners_list,\n",
    "    )\n",
    "\n",
    "    # project is required\n",
    "    if np.isnan(project_id) or project_id == \"\" or not project_id:\n",
    "        record[\"integration_state\"] = \"STOP\"\n",
    "        record[\"integration_state_rule\"] = \"project_is_required\"\n",
    "        logger.warning(\"%s: %s\", record[\"integration_state_rule\"], title)\n",
    "\n",
    "    # rule 1\n",
    "    elif not np.isnan(actual_hours) and len_sessions_list > 0:\n",
    "        record[\"integration_state\"] = \"STOP\"\n",
    "        record[\"integration_state_rule\"] = \"actual_hours_and_sessions\"\n",
    "        logger.warning(\"%s: %s\", record[\"integration_state_rule\"], title)\n",
    "\n",
    "    # rule 2 - using actual hours requires at least one owner\n",
    "    elif not np.isnan(actual_hours) and len_owners_list == 0:\n",
    "        record[\"integration_state\"] = \"STOP\"\n",
    "        record[\"integration_state_rule\"] = \"actual_hours_and_no_owners\"\n",
    "        logger.warning(\"%s: %s\", record[\"integration_state_rule\"], title)\n",
    "\n",
    "    # rule 3\n",
    "    elif np.isnan(actual_hours) and len_sessions_list == 0:\n",
    "        record[\"integration_state\"] = \"STOP\"\n",
    "        record[\"integration_state_rule\"] = \"no_actual_hours_and_no_sessions\"\n",
    "        logger.warning(\"%s: %s\", record[\"integration_state_rule\"], title)\n",
    "\n",
    "    else:\n",
    "        record[\"integration_state\"] = \"Ready\"\n",
    "        record[\"integration_state_rule\"] = \"Ready\"\n",
    "\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f5fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate each record\n",
    "records = tasks_df.reset_index().to_dict(\"records\")\n",
    "\n",
    "vald_recs = []\n",
    "\n",
    "for record in records:\n",
    "    # validate the records\n",
    "    vald_rec = validate_task_record(record)\n",
    "    if vald_rec:\n",
    "        vald_recs.append(vald_rec)\n",
    "\n",
    "df = pd.DataFrame(vald_recs).set_index(\"index\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565becd1",
   "metadata": {},
   "source": [
    "Use prefect and mapping to update the task/item integration status in MDC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(max_retries=3, retry_delay=timedelta(seconds=15))\n",
    "def update_task_integration_status(monday_conn, record):\n",
    "    logger = prefect.context.get(\"logger\")\n",
    "    logger.debug(f\"Updating Monday.com record for {record['Task Name']}\")\n",
    "    monday_conn.items.change_item_value(\n",
    "        TASKS_BOARD_ID,\n",
    "        record[\"task_id\"],\n",
    "        \"text01\",\n",
    "        f\"{record['integration_state_rule']} - {datetime.now()}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb45926",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Flow(\"update monday.com tasks\") as flow:\n",
    "\n",
    "    monday_conn = Parameter(\"monday_conn\")\n",
    "    validated_tasks = Parameter(\"validated_tasks\")\n",
    "\n",
    "    # send updates back to Monday.com... this is all one-way so no reduce required\n",
    "    update_task_integration_status.map(unmapped(monday_conn), validated_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacd01a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"monday_conn\": conn, \"validated_tasks\": vald_recs}\n",
    "state = flow.run(parameters=params, executor=LocalDaskExecutor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b79d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save off an output\n",
    "sb.glue(\"updated_task_count\", len(df))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
